{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72618b0d-b100-40e0-b364-9224161fc317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i writefile2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8487e496-e054-4848-835f-684afbae0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def predict_replace( df, ensemble, verbose = 1 ):\n",
    "\n",
    "    # for predicted time range\n",
    "    \n",
    "    min_start = max([ l.length_l + l.lag for l in ensemble ])\n",
    "    min_length = max([ l.length_r for l in ensemble ])\n",
    "    \n",
    "    start = min_start\n",
    "    length = df.shape[ 0 ] - start\n",
    "    \n",
    "    assert start >= min_start\n",
    "    assert length >= min_length\n",
    "    assert start + length <= df.shape[ 0 ]\n",
    "    \n",
    "    lhs_chunks = [ ]\n",
    "    rhs_chunks = [ ]\n",
    "    weight_chunks = [ ]\n",
    "    \n",
    "    for learner in tqdm( ensemble, file = sys.stdout ):\n",
    "    \n",
    "        n_predictions = 1 + length - learner.length_r\n",
    "        M = learner.linear_operator\n",
    "        n_rows_total = M.shape[ 0 ] * n_predictions\n",
    "        lag = learner.lag\n",
    "    \n",
    "        for i in range( n_predictions ):\n",
    "    \n",
    "            chunk = np.zeros(( M.shape[ 0 ], length ))\n",
    "            chunk[ :, i : i + M.shape[ 1 ]] = M\n",
    "            lhs_chunks.append( chunk )\n",
    "    \n",
    "            window = df.iloc[ start - lag - learner.length_l + i: start - lag + i, : ].to_numpy( )\n",
    "            y = learner.predict( window )\n",
    "            rhs_chunks.append( y )\n",
    "    \n",
    "            # each weak learner is now regarded equally important, independent of total rows occupied\n",
    "            # otherwise learners with smaller windows and larger operators are favoured\n",
    "            weight_chunks.append( np.ones( M.shape[ 0 ], ) * ( learner.weight / n_rows_total ))\n",
    "\n",
    "    lhs = np.concatenate( lhs_chunks, axis = 0 )\n",
    "    rhs = np.concatenate( rhs_chunks, axis = 0 )\n",
    "    weight = np.concatenate( weight_chunks, axis = 0 )\n",
    "    \n",
    "    lhs = np.diag( weight ) @ lhs\n",
    "    rhs = np.diag( weight ) @ rhs\n",
    "    \n",
    "    assert lhs.shape == ( rhs.shape[ 0 ], length )\n",
    "\n",
    "    if verbose >= 1:\n",
    "    \n",
    "        print( f\"lhs shape = { lhs.shape }\" )\n",
    "        print( f\"lhs rank = { np.linalg.matrix_rank( lhs )}\" )\n",
    "        print( f\"degrees of freedom = { length }\" )\n",
    "\n",
    "    prediction, *_ = np.linalg.lstsq( lhs, rhs, rcond = None )\n",
    "\n",
    "    df_pred = df.copy( )\n",
    "    df_pred.iloc[ :, : ] = np.nan\n",
    "    df_pred.iloc[ start : start + length, :3 ] = prediction\n",
    "\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3c23b-c54f-4bb0-b7e5-6c973ef85073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
