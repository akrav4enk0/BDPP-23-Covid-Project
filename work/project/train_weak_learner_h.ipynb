{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca49d44-c0ef-4b1f-895d-60a28611db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i writefile2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90376c38-76fd-43b6-9eae-010d7ec992af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile2 --name weak_learner.py --source train_weak_learner_h.ipynb\n",
    "\n",
    "\"\"\"\n",
    "simple wrapper around the internal model's predict method with some additional checks\n",
    "\"\"\"\n",
    "\n",
    "class weak_learner:\n",
    "\n",
    "    def predict( self, window ):\n",
    "    \n",
    "        assert window.shape == ( self.length_l, self.d )\n",
    "        x = window.reshape( 1, -1, order = \"C\" )\n",
    "        assert x.shape == ( 1, self.length_l * self.d )\n",
    "        y = self.model.predict( x ).squeeze( 0 )\n",
    "        assert y.shape == ( self.linear_operator.shape[ 0 ] * self.n_outcomes, )\n",
    "        y = y.reshape( self.linear_operator.shape[ 0 ], self.n_outcomes )\n",
    "        return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118ce7c5-af38-40b4-b98f-f48758eb46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile2\n",
    "\"\"\"\n",
    "train a weak learner using given right/left window lengths and lag.\n",
    "for learning a (rank-deficient) linear function of the right window use the linear operator.\n",
    "the weak learner can be a linear model or a random forest.\n",
    "trigger this node with verbose settings to see some diagnostic and theory output in LaTeX.\n",
    "\"\"\"\n",
    "\n",
    "import nodes\n",
    "import require\n",
    "\n",
    "@nodes.generic_node\n",
    "def train_weak_learner( \n",
    "\n",
    "        subset = slice( None ), \n",
    "        length_l = 1, \n",
    "        lag = 0, \n",
    "        length_r = 1, \n",
    "        linear_operator = None, \n",
    "        weight = 1, \n",
    "        type = \"lm\",\n",
    "        learner_kwargs = { }\n",
    "    ):\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from IPython.display import display, HTML, Markdown as md\n",
    "    from tqdm import tqdm\n",
    "    import sys\n",
    "    from types import SimpleNamespace as ns\n",
    "    import os\n",
    "    import math\n",
    "        \n",
    "    weak_learner = require.single( \"weak_learner\" )\n",
    "    get_number_of_window_samples = require.single( \"get_number_of_window_samples\" )\n",
    "    display_dict = require.untracked.single( \"display_dict\" )\n",
    "    verbose = require.untracked.single( \"verbose\" )\n",
    "    n_outcomes = len( require.single( \"owid_outcomes\" ))\n",
    "\n",
    "    if linear_operator is None:\n",
    "\n",
    "        #average\n",
    "        linear_operator = np.ones(( 1, length_r )) / length_r\n",
    "    \n",
    "    patch_args = dict( \n",
    "\n",
    "        subset = subset,\n",
    "        length_l = length_l, \n",
    "        lag = lag, \n",
    "        length_r = length_r, \n",
    "        linear_operator = linear_operator \n",
    "    )\n",
    "    \n",
    "    def main( \n",
    "        \n",
    "            patches_node: nodes.find( \"window_patches\" ).given( ** patch_args ),\n",
    "            training_data_node: nodes.find( \"training_data\" ).given( )\n",
    "        ):\n",
    "\n",
    "        self = weak_learner( )\n",
    "        X = patches_node.result.X\n",
    "        Y = patches_node.result.Y\n",
    "        \n",
    "        dataframes = training_data_node.result[ subset ] #currently simple slice indexing\n",
    "\n",
    "        #number of time series\n",
    "        d = dataframes[ 0 ].shape[ 1 ]\n",
    "        get_n_samples = lambda df: get_number_of_window_samples( df, length_l, lag, length_r )\n",
    "        n_samples_total = sum([ get_n_samples( df ) for df in dataframes ])\n",
    "\n",
    "        print( \"training...\" )\n",
    "            \n",
    "        if type == \"lm\":\n",
    "            \n",
    "            from sklearn.linear_model import LinearRegression as lm\n",
    "            return lm( ** learner_kwargs ).fit( X, Y )\n",
    "\n",
    "        if type == \"forest\":\n",
    "\n",
    "            from sklearn.ensemble import RandomForestRegressor as rf\n",
    "\n",
    "            kwargs = learner_kwargs\n",
    "            args = ns( ** kwargs )\n",
    "            \n",
    "            if not hasattr( args, \"n_jobs\" ): \n",
    "                \n",
    "                args.n_jobs = 1\n",
    "            \n",
    "            if args.n_jobs < 0:\n",
    "\n",
    "                args.n_jobs = os.cpu_count( ) + 1 + args.n_jobs\n",
    "\n",
    "            if not hasattr( args, \"n_estimators\" ):\n",
    "\n",
    "                args.n_estimators = 100\n",
    "\n",
    "            n_estimators = args.n_estimators\n",
    "            n_jobs = args.n_jobs\n",
    "            kwargs = args.__dict__\n",
    "            print( kwargs )\n",
    "            model = rf( warm_start = True, oob_score = True, ** kwargs )\n",
    "            \n",
    "            n_steps = int( math.ceil( n_estimators / n_jobs ))\n",
    "            for i in tqdm( range( n_steps ), file = sys.stdout, desc = \"training estimators\" ):\n",
    "\n",
    "                model.set_params( n_estimators = n_jobs * ( i + 1 ), oob_score = i == n_steps - 1 )\n",
    "                model.fit( X, Y )    \n",
    "\n",
    "        print( \"done\" )\n",
    "            \n",
    "        info_dict = {\n",
    "                \n",
    "            \"number of dataframes\": len( dataframes ),\n",
    "            ** { f\"samples from dataframe { i }\": get_n_samples( dataframes[ i ]) for i in range( len( dataframes ))},\n",
    "            \"total number of samples\": n_samples_total,\n",
    "            \"number of time series\": d,\n",
    "            \"number of outcome series\": n_outcomes,\n",
    "            \"length of left/predictor window\": length_l, \n",
    "            \"lag/spacing between windows\": lag, \n",
    "            \"length of right/response window\": length_r,\n",
    "            \"shape of linear operator M\": linear_operator.shape,\n",
    "            \"least squares weight\": weight,\n",
    "            \"score\": model.oob_score_,\n",
    "            \"score type\": \"r2\",\n",
    "            ** kwargs\n",
    "        }\n",
    "            \n",
    "        if verbose( ):\n",
    "    \n",
    "            display( HTML( f\"<h1>Weak Learner Training</h1>\" ))\n",
    "            display( HTML( f\"<h3>Parameters</h3>\" ))\n",
    "            display_dict( info_dict )\n",
    "            display( HTML( f\"<h3>Theory</h3>\" ))\n",
    "            display( md( patches_node.result.info ))            \n",
    "    \n",
    "        self.__dict__.update( \n",
    "\n",
    "            model = model,\n",
    "            length_l = length_l, \n",
    "            lag = lag,\n",
    "            length_r = length_r,\n",
    "            linear_operator = linear_operator,\n",
    "            weight = weight,\n",
    "            d = d,\n",
    "            n_outcomes = n_outcomes,\n",
    "            theory_info = patches_node.result.info,\n",
    "            info_dict = info_dict\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    return main\n",
    "\n",
    "node = train_weak_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d43fa-2729-4eff-9381-1734b2fcb07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
