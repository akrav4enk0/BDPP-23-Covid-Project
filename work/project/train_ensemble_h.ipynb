{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78edd3b9-f885-43bc-a202-bd020ec732da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i writefile2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee1ce15-0dad-4f0d-af7a-1569217e5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile2 --name ensemble.py\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from types import SimpleNamespace as ns\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import require\n",
    "train_weak_learner = require.single( \"train_weak_learner\" )\n",
    "\n",
    "class ensemble:\n",
    "\n",
    "    def train( self, train_set, verbose = 1 ):\n",
    "\n",
    "        if verbose >= 1:\n",
    "\n",
    "            display( HTML( f\"<h1>Ensemble Training</h1>\" ))\n",
    "        \n",
    "        def first_last( l ):\n",
    "    \n",
    "            M = np.zeros(( 2, l ))\n",
    "            M[ 0, 0 ] = 1\n",
    "            M[ 1, l - 1 ] = 1\n",
    "            return M\n",
    "        \n",
    "        def mean( l ):\n",
    "    \n",
    "            return np.ones(( 1, l )) / l\n",
    "    \n",
    "        def gradient( l ):\n",
    "        \n",
    "            grad = np.zeros(( l, l ))\n",
    "            #grad[ np.arange( l - 1 ) + 1, ( np.arange( l - 1 )) % l ] = -1 # for left diagonal\n",
    "            grad[ np.arange( l ), np.arange( l )] = -1\n",
    "            grad[ np.arange( l - 1 ), ( np.arange( l - 1 ) + 1 ) % l ] = 1\n",
    "            return grad\n",
    "        \n",
    "        ensemble = [ ]\n",
    "        length_r = 100\n",
    "        \n",
    "        learner = train_weak_learner( train_set, length_l = length_r, lag = 50, length_r = length_r, linear_operator = mean( length_r ) @ gradient( length_r ) @ gradient( length_r ), verbose = False )    \n",
    "        ensemble.append( learner )\n",
    "        \n",
    "        learner = train_weak_learner( train_set, length_l = length_r, lag = 50, length_r = length_r, linear_operator = mean( length_r ) @ gradient( length_r ), verbose = False )    \n",
    "        ensemble.append( learner )\n",
    "    \n",
    "        self.__dict__.update( ensemble = ensemble )\n",
    "\n",
    "    def predict_replace( self, df, verbose = 1 ):\n",
    "\n",
    "        ensemble = self.ensemble\n",
    "        # for predicted time range\n",
    "        \n",
    "        min_start = max([ l.length_l + l.lag for l in ensemble ])\n",
    "        min_length = max([ l.length_r for l in ensemble ])\n",
    "        \n",
    "        start = min_start\n",
    "        length = df.shape[ 0 ] - start\n",
    "        \n",
    "        assert start >= min_start\n",
    "        assert length >= min_length\n",
    "        assert start + length <= df.shape[ 0 ]\n",
    "        \n",
    "        lhs_chunks = [ ]\n",
    "        rhs_chunks = [ ]\n",
    "        weight_chunks = [ ]\n",
    "        \n",
    "        for learner in tqdm( ensemble, file = sys.stdout ):\n",
    "        \n",
    "            n_predictions = 1 + length - learner.length_r\n",
    "            M = learner.linear_operator\n",
    "            n_rows_total = M.shape[ 0 ] * n_predictions\n",
    "            lag = learner.lag\n",
    "        \n",
    "            for i in range( n_predictions ):\n",
    "        \n",
    "                chunk = np.zeros(( M.shape[ 0 ], length ))\n",
    "                chunk[ :, i : i + M.shape[ 1 ]] = M\n",
    "                lhs_chunks.append( chunk )\n",
    "        \n",
    "                window = df.iloc[ start - lag - learner.length_l + i: start - lag + i, : ].to_numpy( )\n",
    "                y = learner.predict( window )\n",
    "                rhs_chunks.append( y )\n",
    "        \n",
    "                # each weak learner is now regarded equally important, independent of total rows occupied\n",
    "                # otherwise learners with smaller windows and larger operators are favoured\n",
    "                weight_chunks.append( np.ones( M.shape[ 0 ], ) * ( learner.weight / n_rows_total ))\n",
    "    \n",
    "        lhs = np.concatenate( lhs_chunks, axis = 0 )\n",
    "        rhs = np.concatenate( rhs_chunks, axis = 0 )\n",
    "        weight = np.concatenate( weight_chunks, axis = 0 )\n",
    "        \n",
    "        lhs = np.diag( weight ) @ lhs\n",
    "        rhs = np.diag( weight ) @ rhs\n",
    "        \n",
    "        assert lhs.shape == ( rhs.shape[ 0 ], length )\n",
    "    \n",
    "        if verbose >= 1:\n",
    "        \n",
    "            print( f\"lhs shape = { lhs.shape }\" )\n",
    "            print( f\"lhs rank = { np.linalg.matrix_rank( lhs )}\" )\n",
    "            print( f\"degrees of freedom = { length }\" )\n",
    "    \n",
    "        prediction, *_ = np.linalg.lstsq( lhs, rhs, rcond = None )\n",
    "    \n",
    "        df_pred = df.copy( )\n",
    "        df_pred.iloc[ :, : ] = np.nan\n",
    "        df_pred.iloc[ start : start + length, :3 ] = prediction\n",
    "    \n",
    "        return df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb7537a3-22b9-4e88-a4cc-aafd4a21c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile2\n",
    "import nodes\n",
    "import require\n",
    "\n",
    "@nodes.generic_node\n",
    "def training_data( ):\n",
    "\n",
    "    get_training_data = require.single( \"get_training_data\" )\n",
    "    \n",
    "    def main( ):\n",
    "\n",
    "        return get_training_data( verbose = 0 )\n",
    "\n",
    "    return main\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde54e85-861f-4e38-96cd-b1dc73d4f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile2\n",
    "import nodes\n",
    "import require\n",
    "\n",
    "@nodes.generic_node\n",
    "def train_ensemble( ):\n",
    "\n",
    "    ensemble = require.single( \"ensemble\" )\n",
    "    training_data_node = require.single( \"training_data\" )\n",
    "    \n",
    "    def main( training_data: training_data_node.given( )):\n",
    "\n",
    "        e = ensemble( )\n",
    "        e.train( training_data.result, verbose = 1 )\n",
    "        return e\n",
    "\n",
    "    return main\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0234720-9cc0-4fcd-ad3b-0a47f4089e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Ensemble Training</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ensemble.ensemble at 0xffff96c4b3a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ensemble.get_result( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc4609-7f35-4c61-a800-d1daa5fa24bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
