{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78edd3b9-f885-43bc-a202-bd020ec732da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i writefile2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee1ce15-0dad-4f0d-af7a-1569217e5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile2 --name ensemble.py --source train_ensemble_h.ipynb\n",
    "\n",
    "\"\"\"\n",
    "train a belief ensemble of weak learners.\n",
    "beliefs are combined by manually selected weight in a least-squares sense.\n",
    "this model is not an honest/forward model in the sense that it modifies the original\n",
    "data rather than predicting it (counterfactual). validation must be inferred\n",
    "from the weak learners, as the predict_replace method works on the unseen\n",
    "data that would be passed in for validation. it is possible to have\n",
    "a forward-predicting version of this belief ensemble, but since the weak learners \n",
    "vary in structure (window lengths and lag), the implementation is rather involved.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from types import SimpleNamespace as ns\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import require\n",
    "train_weak_learner = require.single( \"train_weak_learner\" )\n",
    "verbose = require.untracked.single( \"verbose\" )\n",
    "n_outcomes = len( require.single( \"owid_outcomes\" ))\n",
    "\n",
    "class ensemble:\n",
    "\n",
    "    def train( self, train_set ):\n",
    "\n",
    "        if verbose( ):\n",
    "\n",
    "            display( HTML( f\"<h1>Ensemble Training</h1>\" ))\n",
    "        \n",
    "        def first_last( l ):\n",
    "    \n",
    "            M = np.zeros(( 2, l ))\n",
    "            M[ 0, 0 ] = 1\n",
    "            M[ 1, l - 1 ] = 1\n",
    "            return M\n",
    "        \n",
    "        def mean( l ):\n",
    "    \n",
    "            return np.ones(( 1, l )) / l\n",
    "    \n",
    "        def gradient( l ):\n",
    "        \n",
    "            grad = np.zeros(( l, l ))\n",
    "            #grad[ np.arange( l - 1 ) + 1, ( np.arange( l - 1 )) % l ] = -1 # for left diagonal\n",
    "            grad[ np.arange( l ), np.arange( l )] = -1\n",
    "            grad[ np.arange( l - 1 ), ( np.arange( l - 1 ) + 1 ) % l ] = 1\n",
    "            return grad\n",
    "        \n",
    "        ensemble = [ ]\n",
    "        length_r = 100\n",
    "        \n",
    "        learner = train_weak_learner( train_set, length_l = length_r, lag = 50, length_r = length_r, linear_operator = mean( length_r ) @ gradient( length_r ) @ gradient( length_r ))    \n",
    "        ensemble.append( learner )\n",
    "        \n",
    "        learner = train_weak_learner( train_set, length_l = length_r, lag = 50, length_r = length_r, linear_operator = mean( length_r ) @ gradient( length_r ))    \n",
    "        ensemble.append( learner )\n",
    "    \n",
    "        self.__dict__.update( ensemble = ensemble )\n",
    "\n",
    "    def predict_replace( self, df, start = None, length = None, callback = None ):\n",
    "\n",
    "        callback = ( lambda * _: None ) if callback is None else callback\n",
    "        ensemble = self.ensemble\n",
    "        # for predicted time range\n",
    "        \n",
    "        min_start = max([ l.length_l + l.lag for l in ensemble ])\n",
    "        min_length = max([ l.length_r for l in ensemble ])\n",
    "        \n",
    "        start = min_start if start is None else start\n",
    "        start = max( start, min_start )\n",
    "        length = df.shape[ 0 ] - start if length is None else length\n",
    "        assert length >= min_length\n",
    "        assert start + length <= df.shape[ 0 ]\n",
    "        \n",
    "        lhs_chunks = [ ]\n",
    "        rhs_chunks = [ ]\n",
    "        weight_chunks = [ ]\n",
    "\n",
    "        n_predictions_total = sum([ 1 + length - learner.length_r for learner in ensemble ])\n",
    "        n_predictions_done = 0\n",
    "        \n",
    "        for learner in tqdm( ensemble, file = sys.stdout, desc = \"training ensemble\" ):\n",
    "        \n",
    "            n_predictions = 1 + length - learner.length_r\n",
    "            M = learner.linear_operator\n",
    "            n_rows_total = M.shape[ 0 ] * n_predictions\n",
    "            lag = learner.lag\n",
    "        \n",
    "            for i in range( n_predictions ):\n",
    "        \n",
    "                chunk = np.zeros(( M.shape[ 0 ], length ))\n",
    "                chunk[ :, i : i + M.shape[ 1 ]] = M\n",
    "                lhs_chunks.append( chunk )\n",
    "        \n",
    "                window = df.iloc[ start - lag - learner.length_l + i: start - lag + i, : ].to_numpy( )\n",
    "                y = learner.predict( window )\n",
    "                rhs_chunks.append( y )\n",
    "        \n",
    "                # each weak learner is now regarded equally important, independent of total rows occupied\n",
    "                # otherwise learners with smaller windows and larger operators are favoured\n",
    "                weight_chunks.append( np.ones( M.shape[ 0 ], ) * ( learner.weight / n_rows_total ))\n",
    "\n",
    "                n_predictions_done += 1\n",
    "                callback( n_predictions_done / n_predictions_total )\n",
    "    \n",
    "        lhs = np.concatenate( lhs_chunks, axis = 0 )\n",
    "        rhs = np.concatenate( rhs_chunks, axis = 0 )\n",
    "        weight = np.concatenate( weight_chunks, axis = 0 )\n",
    "        \n",
    "        lhs = np.diag( weight ) @ lhs\n",
    "        rhs = np.diag( weight ) @ rhs\n",
    "        \n",
    "        assert lhs.shape == ( rhs.shape[ 0 ], length )\n",
    "    \n",
    "        if verbose( ):\n",
    "        \n",
    "            print( f\"lhs shape = { lhs.shape }\" )\n",
    "            print( f\"lhs rank = { np.linalg.matrix_rank( lhs )}\" )\n",
    "            print( f\"degrees of freedom = { length }\" )\n",
    "    \n",
    "        prediction, *_ = np.linalg.lstsq( lhs, rhs, rcond = None )\n",
    "    \n",
    "        df_pred = df.copy( )\n",
    "        df_pred.iloc[ start : start + length, :n_outcomes ] = prediction\n",
    "    \n",
    "        return df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0234720-9cc0-4fcd-ad3b-0a47f4089e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ensemble.ensemble at 0xffff72999190>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import verbose\n",
    "verbose.set_level( 0 )\n",
    "train_ensemble.get_result( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41be2e7f-606b-46ef-8a98-d0bc509bda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile2\n",
    "\n",
    "\"\"\"\n",
    "cache node wrapper around ensemble.py and training_data.py that caches the trained model\n",
    "\"\"\"\n",
    "\n",
    "import nodes\n",
    "import require\n",
    "\n",
    "@nodes.generic_node\n",
    "def train_ensemble( ):\n",
    "\n",
    "    ensemble = require.single( \"ensemble\" )\n",
    "    training_data_node = require.single( \"training_data\" )\n",
    "    \n",
    "    def main( training_data: training_data_node.given( )):\n",
    "\n",
    "        e = ensemble( )\n",
    "        e.train( training_data.result )\n",
    "        return e\n",
    "\n",
    "    return main\n",
    "\n",
    "node = train_ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
